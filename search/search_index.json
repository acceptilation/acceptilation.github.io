{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Notes","text":"<p>My notes in the form of an MkDocs site</p>"},{"location":"#python-setup","title":"Python setup","text":"<pre><code>sudo apt install python3-full;\npython3 -m venv ./.venv;\nsource ./.venv/bin/activate;\npip install --requirement requirements.txt;\n</code></pre>"},{"location":"#run-mkdocs","title":"Run MkDocs","text":"<pre><code>mkdocs serve;\n</code></pre>"},{"location":"#jetbrains-run-configuration","title":"JetBrains run configuration","text":"<p>To run site locally: <code>mkdocs-serve</code></p>"},{"location":"reference/concourse/","title":"Concourse Reference","text":"<p>The <code>fly</code> tool is used to update Concourse pipelines.</p>"},{"location":"reference/concourse/#set-up-fly","title":"Set up Fly","text":"<pre><code>brew install fly;\nfly --target=foo login --team-name=bar --concourse-url=https://example.com/;\n# click the output browser link to log in\nfly --target=foo sync;\n</code></pre>"},{"location":"reference/concourse/#inspect-pipeline-containers","title":"Inspect pipeline containers","text":"<p>Should a pipeline fail, Concourse preserves the containers for inspection, e.g.:</p> <pre><code>fly intercept --target=foo --job=bar/baz;\n</code></pre>"},{"location":"reference/concourse/#download-reports","title":"Download reports","text":"<pre><code># connect to container\nfly intercept --target=foo --job=bar/baz;\n\n# within container, create archive of report\ncd git/foo/build/reports/tests/;\ntar -vzcf test.tar.gz test;\n# note path to archive, e.g. /tmp/build/80754af9/git/foo/build/reports/tests/test.tar.gz\nexit;\n\n# cat container archive to local archive\nfly hijack \\\n    --target=foo \\\n    --job=bar/baz \\\n    --build=7 \\\n    --step=build \\\n    cat /tmp/build/80754af9/git/foo/build/reports/tests/test.tar.gz &gt; ./test.tar.gz;\n</code></pre>"},{"location":"reference/jetbrains/","title":"JetBrains Reference","text":"<p>Here are some plugins and settings that are useful for JetBrains IDEs.</p>"},{"location":"reference/jetbrains/#plugins","title":"Plugins","text":"<ol> <li>Atom material icons</li> <li>Material theme UI</li> </ol>"},{"location":"reference/jetbrains/#settings","title":"Settings","text":"<p>Here's where to find settings for IntelliJ Idea, Rider, etc. that usually need to change:</p> Setting Location Code folding Editor \u2192 General \u2192 Code folding Compare with branch Keymap \u2192 Compare with branch... EOF Editor \u2192 General \u2192 Ensure every saved file ends with a line break File colors Appearance &amp; Behavior \u2192 File Colors \u2192 Enable file colors Inlays Editor \u2192 Inlay hints Intention bulb Editor \u2192 General \u2192 Appearance \u2192 Show intention bulb Italics Editor \u2192 Color scheme \u2192 General Line comments Editor \u2192 Code style \u2192 Kotlin \u2192 Code generation \u2192 Line comment at first column New UI Appearance &amp; behavior \u2192 New UI \u2192 Enable new UI Preview tab Project widget \u2192 Enable preview tab Properties files Editor \u2192 Code style \u2192 Properties \u2192 Keep blank lines Terminal spacing Editor \u2192 Color scheme \u2192 Console font \u2192 Line height Wildcard imports Editor \u2192 Code style \u2192 Kotlin \u2192 Imports \u2192 Use import with '*'"},{"location":"reference/python-kafka/","title":"Python-Kafka Reference","text":"<pre><code># A Python script for consuming a Kafka topic and writing it to file\n# Sources:\n#     https://www.slingacademy.com/article/how-to-write-a-kafka-consumer-in-python/\n#     https://stackoverflow.com/questions/44407780/how-to-decode-deserialize-avro-with-python-from-kafka\n\nimport io\n\nimport avro.schema\nfrom avro.io import DatumReader, BinaryDecoder\nfrom confluent_kafka import Consumer, KafkaError\n\n\ndef print_assignment(_, partitions):\n    print('Assignment:', partitions)\n\n\ndef decode(bytes_msg):\n    bytes_io = io.BytesIO(bytes_msg)\n    bytes_io.seek(5)  # Confluent adds 5 extra bytes before the typical Avro-formatted data\n    decoder = BinaryDecoder(bytes_io)\n    return datum_reader.read(decoder)\n\n\nconf = {\n    'bootstrap.servers': 'hostname:port',  # todo: add server\n    'security.protocol': 'protocol',  # todo: add security protocol\n    'sasl.mechanism': 'mechanism',  # todo: add SASL mechanism\n    'sasl.username': 'username',  # todo: add username\n    'sasl.password': 'password',  # todo: add password\n    'group.id': 'group-id',  # todo: add group ID\n    'auto.offset.reset': 'earliest'\n}\n\nschema = avro.schema.parse(open('topic-schema.avsc').read())  # todo: add schema file\ndatum_reader = DatumReader(schema)\n\nconsumer = Consumer(conf)\nconsumer.subscribe(['topic-name'], on_assign=print_assignment)  # todo: add topic name\n\nwith open('output.csv', 'w') as csv_file:\n    while True:\n        msg = consumer.poll(1.0)\n\n        if msg is None:\n            continue\n        if msg.error():\n            # noinspection PyProtectedMember\n            if msg.error().code() == KafkaError._PARTITION_EOF:\n                continue\n            else:\n                print(msg.error())\n                break\n\n        # noinspection PyArgumentList\n        msg_value = msg.value()\n        msg_dict = decode(msg_value)\n        msg_str = str(msg_dict)\n\n        # format the string for import via Conduktor\n        dq_str = msg_str.replace('\\'', '\"\"')\n        formatted_str = '\"{}\";\"{}\"\\n'.format(dq_str, dq_str)  # in this case, output key and value were identical\n        csv_file.write(formatted_str)\n        print(formatted_str)\n\nconsumer.close()\n</code></pre>"},{"location":"setup/azure-functions-app/","title":"Azure Functions App Setup","text":"<p>Follow these steps to create an Azure Functions app.</p> <p>Where did these commands come from?</p> <p>The <code>func</code> commands mentioned below were recommended by the Azure Functions web application, specifically the \"create function\" dialog that pops up when adding a function to an existing Azure Functions app.</p>"},{"location":"setup/azure-functions-app/#install-azure-functions-core-tools","title":"Install Azure Functions core tools","text":"<p>Installing the Azure Functions core tools grants access to the <code>func</code> program.</p> <pre><code>npm install --global azure-functions-core-tools;\n</code></pre>"},{"location":"setup/azure-functions-app/#initialize-app","title":"Initialize app","text":"<pre><code>mkdir FunctionApp;\ncd FunctionApp;\n\nfunc init;\n# when prompted, select \"dotnet (isolated process)\" for the worker runtime\n# when prompted, select \"c#-isolated\" for the language\n</code></pre>"},{"location":"setup/azure-functions-app/#generate-function","title":"Generate function","text":"<pre><code>func new;\n# when prompted, select \"BlobTrigger\" as the template\n# when prompted, use \"LoggingFunction\" as the function name\n</code></pre>"},{"location":"setup/azure-functions-app/#configure-net","title":"Configure .Net","text":"<p>Install the latest version of the .Net framework:</p> <pre><code>brew install dotnet;\n</code></pre> <p>The new app was likely initialized to use an older version of .Net. To upgrade the app's .Net version:</p> <ol> <li>Import the project into Rider.</li> <li>Right-click the project in the solution view of the explorer panel.</li> <li>Select \"Properties...\".</li> <li>Upgrade the .Net version using the dropdown menu.</li> </ol> <p>To verify the update:</p> <ol> <li>Go to the file system view of the explorer panel.</li> <li>Open the <code>csproj</code> file.</li> <li>Verify the value within the <code>TargetFramework</code> tags.</li> </ol> <p>Updating the C# project file</p> <p>Most configurations that impact the <code>csproj</code> file -- version upgrades, package installations, etc. -- can be performed in the Rider UI, which will generate the corresponding XML. Direct editing of the project file is rarely required.</p>"},{"location":"setup/azure-functions-app/#run-storage-emulator","title":"Run storage emulator","text":"<p>The new function triggers on blob storage activity. Therefore, to test the function locally, a local emulator must pretend to be an Azure Storage account. Enter Azurite:</p> <pre><code>docker pull mcr.microsoft.com/azure-storage/azurite;\n\ndocker run --detach \\\n    --publish 10000:10000 \\\n    --publish 10001:10001 \\\n    --publish 10002:10002 \\\n    mcr.microsoft.com/azure-storage/azurite;\n</code></pre> <p>Azurite ports</p> <p>By default, Azurite uses three ports for its three services: its blob service uses port 10,000, its queue service uses port 10,001, and its table service uses port 10,002.</p>"},{"location":"setup/azure-functions-app/#run-storage-explorer","title":"Run storage explorer","text":"<p>To interact with the storage emulator:</p> <ol> <li>Download and run Azure Storage Explorer.</li> <li>In the \"Get Started\" tab, select \"Attach to a resource\".</li> <li>Select \"Local storage emulator\".</li> <li>Accept the default setup.</li> <li>Expand the resulting storage account in the explorer panel.</li> <li>Right-click \"Blob Containers\".</li> <li>Select \"Create Blob Container\".</li> <li>Name the new blob container <code>samples-workitems</code>.</li> </ol> <p>Blob container names</p> <p>Technically, the new blob container can be named anything, but <code>samples-workitems</code> is the name already used by the generated app. Try searching the project for where it appears!</p>"},{"location":"setup/azure-functions-app/#simulate-environment-variable","title":"Simulate environment variable","text":"<p>When running in Azure, functions get environment variables from their parent app's settings. When running locally, however, functions will pull environment variables from <code>local.settings.json</code>.</p> <p>To demonstrate this, add a string to the <code>Values</code> object:</p> local.settings.json<pre><code>{\n  \"IsEncrypted\": false,\n  \"Values\": {\n    \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\",\n    \"FUNCTIONS_WORKER_RUNTIME\": \"dotnet-isolated\",\n    \"GREETING\": \"Hello, world!\"\n  }\n}\n</code></pre> <p>Then update <code>LoggingFunction</code> to log the value of the environment variable:</p> LoggingFunction.cs<pre><code>_logger.LogInformation(\n    \"Greeting: {Greeting}\",\n    Environment.GetEnvironmentVariable(\"GREETING\")\n);\n</code></pre>"},{"location":"setup/azure-functions-app/#start-app","title":"Start app","text":"<pre><code>func start;\n</code></pre>"},{"location":"setup/azure-functions-app/#trigger-function","title":"Trigger function","text":"<p>Create a file that will be used to trigger the function:</p> <pre><code>echo \"bar\" &gt; foo.txt;\n</code></pre> <ol> <li>Return to Azure Storage Explorer.</li> <li>Open the <code>samples-workitems</code> container.</li> <li>Select \"Upload\" \u2192 \"Upload Files...\".</li> <li>Upload <code>foo.txt</code> using the defaults.</li> <li>Return to the running app.</li> </ol> <p>Log output should show:</p> <ol> <li>The function was triggered</li> <li>The name of the blob/file that triggered the function</li> <li>The content of the blob</li> <li>The value of the <code>GREETING</code> environment variable</li> </ol>"},{"location":"setup/azure-functions-app/#deploy-function","title":"Deploy function","text":""},{"location":"setup/azure-functions-app/#from-local-machine","title":"From local machine","text":"<p>Deploying from a local machine</p> <p>Early in development, it may make sense to deploy a work-in-progress function directly from a local machine. It shouldn't be long, however, until a remote pipeline assumes deployment responsibilities.</p> <p>Deploying a function requires the Azure CLI:</p> <pre><code>brew install azure-cli;\n</code></pre> <p>Log in with your Azure credentials, then publish the function to the target Azure Functions app:</p> <pre><code>az login;\nfunc azure functionapp publish FunctionApp;\n</code></pre>"},{"location":"setup/azure-functions-app/#from-github-pipeline","title":"From GitHub pipeline","text":"<p>Microsoft has developed a GitHub action for deploying functions to Azure. This action may use an Azure \"publish profile\" in XML format. To download an Azure app's publish profile, find the app in the Azure web UI. At the top of the page will be a button labeled \"Get publish profile\".</p>"},{"location":"setup/github-repository/","title":"GitHub Repository Setup","text":"<p>Follow these steps to set up new GitHub repositories and their pull requests.</p>"},{"location":"setup/github-repository/#create-new-repository","title":"Create new repository","text":"<ul> <li> Give the repository a proper name.<ul> <li>Is a certain prefix required?</li> <li>Should a certain word be included?</li> </ul> </li> <li> Add a repository description and website.</li> <li> Use <code>main</code> as the default branch.</li> <li> Disable unused features:<ul> <li>Wikis</li> <li>Issues</li> <li>Projects</li> </ul> </li> <li> Configure team access.</li> <li> Protect the <code>main</code> branch:<ul> <li>Require a pull request before merging.</li> <li>Require at least 1 approval.</li> <li>Dismiss stale pull request approvals when new commits are pushed.</li> <li>Require conversation resolution before merging.</li> <li>Do not allow bypassing the above settings.</li> </ul> </li> <li> Create GitHub environments:<ul> <li>Development</li> <li>Staging</li> <li>Production</li> </ul> </li> <li> Add Actions repository secrets, e.g. Vault credentials.</li> </ul>"},{"location":"setup/github-repository/#configure-pull-request","title":"Configure pull request","text":""},{"location":"setup/github-repository/#template","title":"Template","text":"<p>Pull request descriptions should follow a template. The template generally looks like this:</p> <pre><code>Jira issue: [ABC-???](https://example.atlassian.net/browse/ABC-???)\n\n### Added\n\n- Added some feature so that a business or technical goal could be achieved\n\n### Changed\n\n- Changed previous intentional behavior so that a business or technical goal could work in a new way instead\n\n### Fixed\n\n- Fixed previous unintentional behavior so that intended business or technical behavior occurs instead\n\n### Removed\n\n- Removed previous capability because reasons why capability is no longer needed\n</code></pre>"},{"location":"setup/github-repository/#merge-strategy","title":"Merge strategy","text":"<p>When merging pull requests, the squash merge is typically preferred. The resulting commit message with its link to the pull request works well with GitHub's generated release notes.</p>"},{"location":"setup/remote-redis-connection/","title":"Remote Redis Connection Setup","text":"<p>Follow these steps to interact with an Azure Redis from a local machine.</p>"},{"location":"setup/remote-redis-connection/#install-command-line-tools","title":"Install command line tools","text":"<pre><code>brew install redis; # (1)!\nbrew install stunnel; # (2)!\n</code></pre> <ol> <li>The Redis command line interface</li> <li>A tool for SSL tunneling</li> </ol>"},{"location":"setup/remote-redis-connection/#fetch-access-key","title":"Fetch access key","text":"<p>Go to the Azure portal and look up the target Redis resource. The resource page will have an \"Access keys\" link under the \"Settings\" section of the left navigation. Note the following information, which will be used to configure the local machine:</p> <ol> <li>Primary access key</li> <li>Host and port, e.g. my-resource.redis.cache.windows.net:6380</li> </ol> <p>Save the access key to the <code>REDISCLI_AUTH</code> environment variable, e.g. add the following line to <code>~/.zshrc</code>:</p> <pre><code>export REDISCLI_AUTH=\"&lt;access token&gt;\"\n</code></pre>"},{"location":"setup/remote-redis-connection/#configure-stunnel","title":"Configure Stunnel","text":"<p>If it doesn't exist already, create a Stunnel configuration file at <code>/usr/local/etc/stunnel/stunnel.conf</code>. Add the following entry to it:</p> <pre><code>[redis-cli]\nclient = yes\naccept = 127.0.0.1:6380\nconnect = &lt;host and port copied from Azure&gt;\n</code></pre>"},{"location":"setup/remote-redis-connection/#connect-to-redis","title":"Connect to Redis","text":"<pre><code>stunnel;\nredis-cli -p 6380; # (1)!\n</code></pre> <ol> <li>Uses the value of <code>REDISCLI_AUTH</code> for the password</li> </ol>"},{"location":"setup/remote-redis-connection/#execute-redis-commands","title":"Execute Redis commands","text":"<pre><code>ping\nkeys *\nsmembers my-set\n</code></pre>"},{"location":"setup/safe/","title":"Safe Setup","text":"<p>Follow these steps to interact with Vault via the Safe command line interface.</p>"},{"location":"setup/safe/#install-safe","title":"Install Safe","text":"<pre><code>brew install starkandwayne/cf/safe;\nsafe --version;\n</code></pre>"},{"location":"setup/safe/#target-vault","title":"Target Vault","text":"<pre><code>safe target [url] [alias];\n</code></pre>"},{"location":"setup/safe/#log-in","title":"Log in","text":"<pre><code>safe auth ldap;\n</code></pre>"},{"location":"setup/safe/#execute-commands","title":"Execute commands","text":"<pre><code>safe tree some/path;\nsafe get some/path/to/secret;\n</code></pre>"},{"location":"setup/sonar/","title":"Sonar Setup","text":"<p>Follow these steps to submit coverage reports and source code to SonarQube.</p>"},{"location":"setup/sonar/#sonarqube-setup","title":"SonarQube setup","text":""},{"location":"setup/sonar/#add-project","title":"Add project","text":"<ol> <li>In SonarQube's top navigation, select \"Projects\".</li> <li>From the \"Create Project\" dropdown menu in the upper right, select \"GitHub\".</li> <li>Search for the target repository, then select \"Set up selected repository\".</li> </ol>"},{"location":"setup/sonar/#set-permissions","title":"Set permissions","text":"<ol> <li>Go to the target project in SonarQube.</li> <li>From the \"Project Settings\" dropdown menu in the upper right, select \"Permissions\".</li> <li>Grant team group all permissions to manage the project.</li> <li>Ask another group member to remove your specific user's permissions because you cannot remove yourself.</li> </ol>"},{"location":"setup/sonar/#get-project-key","title":"Get project key","text":"<ol> <li>Go to the target project in SonarQube.</li> <li>Select \"Project information\" in the upper right and note the project key.</li> </ol> <p>Gradle projects use this project key in their <code>build.gradle.kts</code> file. .Net projects use this project key as a workflow input.</p>"},{"location":"setup/sonar/#create-quality-gate","title":"Create quality gate","text":"<ol> <li>Select \"Quality Gates\" from the top navigation.</li> <li>Select \"DEFAULT QUALITY GATE\" from the list of quality gates.</li> <li>Select \"Copy\" in the upper right.</li> <li>Name the new quality gate, e.g. the name of the team.</li> <li>Increase required coverage to 90%.</li> <li>Grant team group permission to manage this quality gate.</li> </ol>"},{"location":"setup/sonar/#apply-quality-gate","title":"Apply quality gate","text":"<ol> <li>Go to the target project in SonarQube.</li> <li>From the \"Project Settings\" dropdown menu in the upper right, select \"Quality Gate\".</li> <li>Always use a specific Quality Gate: the gate created in the previous step.</li> <li>Select \"Save\".</li> </ol>"},{"location":"setup/sonar/#repository-setup","title":"Repository setup","text":""},{"location":"setup/sonar/#apply-gradle-project-key","title":"Apply Gradle project key","text":"<p>In a Gradle project's <code>build.gradle.kts</code> file, set <code>sonar.projectKey</code> to the key copied from SonarQube:</p> <pre><code>sonarqube {\n    properties {\n        property(\"sonar.projectKey\", \"project_key_goes_here\")\n    }\n}\n</code></pre>"},{"location":"setup/sonar/#apply-net-project-key","title":"Apply .Net project key","text":"<p>In a .Net project's workflows, set <code>sonar-key</code> to the key copied from SonarQube:</p> <pre><code>jobs:\n  test:\n    uses: some-org/pipelines-repo/.github/workflows/dotnet-test.yaml@v1\n    with:\n      sonar-key: project_key_goes_here\n</code></pre>"}]}